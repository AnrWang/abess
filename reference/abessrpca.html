<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Adaptive best subset selection for principal component analysis — abessrpca • abess</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous"><link href="../docsearch.css" rel="stylesheet"><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Adaptive best subset selection for principal component analysis — abessrpca"><meta property="og:description" content="Decompose a matrix into the summation of
low-rank matrix and sparse matrix via the best subset selection approach"><meta property="og:image" content="https://abess-team.github.io/abess/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.4.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/v01-abess-guide.html">Quick start for `abess`: Linear regression</a>
    </li>
    <li>
      <a href="../articles/v03-classification.html">Classification: Logistic Regression and Multinomial Extension</a>
    </li>
    <li>
      <a href="../articles/v04-PoissonGammaReg.html">Positive response: Poisson and Gamma regression</a>
    </li>
    <li>
      <a href="../articles/v05-coxreg.html">Best Subset Selection for Censored Response</a>
    </li>
    <li>
      <a href="../articles/v06-MultiTaskLearning.html">Multi-Response Linear Regression</a>
    </li>
    <li>
      <a href="../articles/v07-advancedFeatures.html">Advanced Features</a>
    </li>
    <li>
      <a href="../articles/v08-sPCA.html">Principal component analysis</a>
    </li>
    <li>
      <a href="../articles/v09-fasterSetting.html">Tips for faster computation</a>
    </li>
    <li>
      <a href="../articles/v10-algorithm.html">ABESS algorithm: details</a>
    </li>
    <li>
      <a href="../articles/v11-power-of-abess.html">Power of abess</a>
    </li>
  </ul></li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/abess-team/abess/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul><form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off"></div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Adaptive best subset selection for principal component analysis</h1>
    <small class="dont-index">Source: <a href="https://github.com/abess-team/abess/tree/master/R-package/R/abessrpca.R" class="external-link"><code>R/abessrpca.R</code></a></small>
    <div class="hidden name"><code>abessrpca.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Decompose a matrix into the summation of
low-rank matrix and sparse matrix via the best subset selection approach</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="fu">abessrpca</span><span class="op">(</span>
  <span class="va">x</span>,
  <span class="va">rank</span>,
  support.size <span class="op">=</span> <span class="cn">NULL</span>,
  tune.path <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"sequence"</span>, <span class="st">"gsection"</span><span class="op">)</span>,
  gs.range <span class="op">=</span> <span class="cn">NULL</span>,
  tune.type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gic"</span>, <span class="st">"aic"</span>, <span class="st">"bic"</span>, <span class="st">"ebic"</span><span class="op">)</span>,
  ic.scale <span class="op">=</span> <span class="fl">1</span>,
  lambda <span class="op">=</span> <span class="fl">0</span>,
  always.include <span class="op">=</span> <span class="cn">NULL</span>,
  group.index <span class="op">=</span> <span class="cn">NULL</span>,
  c.max <span class="op">=</span> <span class="cn">NULL</span>,
  splicing.type <span class="op">=</span> <span class="fl">2</span>,
  max.splicing.iter <span class="op">=</span> <span class="fl">1</span>,
  warm.start <span class="op">=</span> <span class="cn">TRUE</span>,
  important.search <span class="op">=</span> <span class="cn">NULL</span>,
  max.newton.iter <span class="op">=</span> <span class="fl">1</span>,
  newton.thresh <span class="op">=</span> <span class="fl">0.001</span>,
  num.threads <span class="op">=</span> <span class="fl">0</span>,
  seed <span class="op">=</span> <span class="fl">1</span>,
  <span class="va">...</span>
<span class="op">)</span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>x</dt>
<dd><p>A matrix object.</p></dd>
<dt>rank</dt>
<dd><p>The rank of the low-rank matrix.</p></dd>
<dt>support.size</dt>
<dd><p>An integer vector representing the alternative support sizes. 
Only used for tune.path = "sequence". Strongly suggest its minimum value larger than <code>min(dim(x))</code>.</p></dd>
<dt>tune.path</dt>
<dd><p>The method to be used to select the optimal support size. For
<code>tune.path = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>tune.path = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p></dd>
<dt>gs.range</dt>
<dd><p>A integer vector with two elements.
The first element is the minimum model size considered by golden-section,
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.
Not available now.</p></dd>
<dt>tune.type</dt>
<dd><p>The type of criterion for choosing the support size. Available options are "gic", "ebic", "bic" and "aic". 
Default is "gic".</p></dd>
<dt>ic.scale</dt>
<dd><p>A non-negative value used for multiplying the penalty term
in information criterion. Default: <code>ic.scale = 1</code>.</p></dd>
<dt>lambda</dt>
<dd><p>A single lambda value for regularized best subset selection. Default is 0.</p></dd>
<dt>always.include</dt>
<dd><p>An integer vector containing the indexes of variables that should always be included in the model.</p></dd>
<dt>group.index</dt>
<dd><p>A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code> (the default).</p></dd>
<dt>c.max</dt>
<dd><p>an integer splicing size. Default is: <code>c.max = 2</code>.</p></dd>
<dt>splicing.type</dt>
<dd><p>Optional type for splicing.
If <code>splicing.type = 1</code>, the number of variables to be spliced is
<code>c.max</code>, ..., <code>1</code>; if <code>splicing.type = 2</code>,
the number of variables to be spliced is <code>c.max</code>, <code>c.max/2</code>, ..., <code>1</code>.
(Default: <code>splicing.type = 2</code>.)</p></dd>
<dt>max.splicing.iter</dt>
<dd><p>The maximum number of performing splicing algorithm.
In most of the case, only a few times of splicing iteration can guarantee the convergence.
Default is <code>max.splicing.iter = 20</code>.</p></dd>
<dt>warm.start</dt>
<dd><p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p></dd>
<dt>important.search</dt>
<dd><p>An integer number indicating the number of
important variables to be splicing.
When <code>important.search</code> \(\ll\) <code>p</code> variables,
it would greatly reduce runtimes. Default: <code>important.search = 128</code>.</p></dd>
<dt>max.newton.iter</dt>
<dd><p>a integer giving the maximal number of Newton's iteration iterations.
Default is <code>max.newton.iter = 10</code> if <code>newton = "exact"</code>, and <code>max.newton.iter = 60</code> if <code>newton = "approx"</code>.</p></dd>
<dt>newton.thresh</dt>
<dd><p>a numeric value for controlling positive convergence tolerance.
The Newton's iterations converge when \(|dev - dev_{old}|/(|dev| + 0.1)&lt;\) <code>newton.thresh</code>.</p></dd>
<dt>num.threads</dt>
<dd><p>An integer decide the number of threads to be
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>).
If <code>num.threads = 0</code>, then all of available cores will be used.
Default: <code>num.threads = 0</code>.</p></dd>
<dt>seed</dt>
<dd><p>Seed to be used to divide the sample into cross-validation folds.
Default is <code>seed = 1</code>.</p></dd>
<dt>...</dt>
<dd><p>further arguments to be passed to or from methods.</p></dd>
</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>A S3 <code>abessrpca</code> class object, which is a <code>list</code> with the following components:</p>
<dl><dt>S</dt>
<dd><p>A list with <code>length(support.size)</code> elements,
each of which is a sparse matrix estimation;</p></dd>
<dt>L</dt>
<dd><p>The low rank matrix estimation.</p></dd>
<dt>nobs</dt>
<dd><p>The number of sample used for training.</p></dd>
<dt>nvars</dt>
<dd><p>The number of variables used for training.</p></dd>
<dt>rank</dt>
<dd><p>The rank of matrix <code>L</code>.</p></dd>
<dt>loss</dt>
<dd><p>The loss of objective function.</p></dd>
<dt>tune.value</dt>
<dd><p>A value of tuning criterion of length <code>length(support.size)</code>.</p></dd>
<dt>support.size</dt>
<dd><p>The actual support.size values used.
Note that it is not necessary the same as the input if the later have non-integer values or duplicated values.</p></dd>
<dt>tune.type</dt>
<dd><p>The criterion type for tuning parameters.</p></dd>
<dt>call</dt>
<dd><p>The original call to <code>abessrpca</code>.</p></dd>
</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p>Adaptive best subset selection for robust principal component analysis aim to find two latent matrices \(L\) and \(S\) such that the original matrix \(X\) can be appropriately approximated:
$$x = L + S + N,$$ 
where \(L\) is a low-rank matrix, \(S\) is a sparse matrix, \(N\) is a dense noise matrix. 
Generic splicing technique can be employed to solve this problem by iteratively improve the quality of the estimation of \(S\).</p>
<p>For a given support set \(\Omega\), the optimization problem: 
$$\min_S \| x - L - S\|_F^2 \;\;{\rm s.t.}\;\; S_{ij} = 0 {\rm for } (i, j) \in \Omega^c,$$
still a non-convex optimization problem. We use the hard-impute algorithm proposed in one of the reference to solve this problem. 
The hard-impute algorithm is an iterative algorithm, people can set <code>max.newton.iter</code> and <code>newton.thresh</code> to 
control the solution precision of the optimization problem. 
(Here, the name of the two parameters are somehow abused to make the parameters cross functions have an unified name.) 
According to our experiments, 
we assign properly parameters to the two parameter as the default such that the precision and runtime are well balanced, 
we suggest users keep the default values unchanged.</p>
    </div>
    <div id="note">
    <h2>Note</h2>
    <p>Some parameters not described in the Details Section is explained in the document for <code><a href="abess.html">abess</a></code> 
because the meaning of these parameters are very similar.</p>
<p>At present, \(l_2\) regularization and group selection are not support, 
and thus, set <code>lambda</code> and <code>group.index</code> have no influence on the output. 
This feature will coming soon.</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; doi: <a href="https://doi.org/10.1073/pnas.2014241117" class="external-link">10.1073/pnas.2014241117</a></p>
<p>Emmanuel J. Candès, Xiaodong Li, Yi Ma, and John Wright. 2011. Robust principal component analysis? Journal of the ACM. 58, 3, Article 11 (May 2011), 37 pages. doi: <a href="https://doi.org/10.1145/1970392.1970395" class="external-link">10.1145/1970392.1970395</a></p>
<p>Mazumder, Rahul, Trevor Hastie, and Robert Tibshirani. Spectral regularization algorithms for learning large incomplete matrices. The Journal of Machine Learning Research 11 (2010): 2287-2322.</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span class="co"># \donttest{</span></span>
<span class="r-in"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/abess-team/abess" class="external-link">abess</a></span><span class="op">)</span></span>
<span class="r-in"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span class="r-in"><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span class="r-in"><span class="va">true_S_size</span> <span class="op">&lt;-</span> <span class="fl">300</span></span>
<span class="r-in"><span class="va">true_L_rank</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span class="r-in"><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="generate.matrix.html">generate.matrix</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">p</span>, support.size <span class="op">=</span> <span class="va">true_S_size</span>, rank <span class="op">=</span> <span class="va">true_L_rank</span><span class="op">)</span></span>
<span class="r-in"><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">abessrpca</span><span class="op">(</span><span class="va">dataset</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, rank <span class="op">=</span> <span class="va">true_L_rank</span>, support.size <span class="op">=</span> <span class="op">(</span><span class="fl">20</span><span class="op">:</span><span class="fl">40</span><span class="op">)</span> <span class="op">*</span> <span class="fl">10</span><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> abessrpca(x = dataset[["x"]], rank = true_L_rank, support.size = (20:40) * </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     10)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    support.size        loss       gic</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1           200 0.005262884 -1580.424</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2           210 0.004572798 -1649.701</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3           220 0.004013043 -1723.409</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4           230 0.003519668 -1773.783</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5           240 0.002772403 -2619.448</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6           250 0.002233288 -2626.077</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 7           260 0.002120067 -2507.839</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 8           270 0.002041621 -2520.893</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 9           280 0.002011756 -2534.617</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 10          290 0.001800427 -2771.953</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 11          300 0.001789019 -2718.475</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 12          310 0.001681127 -2780.460</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 13          320 0.001594270 -2354.880</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 14          330 0.001469861 -2545.428</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 15          340 0.001392446 -2574.207</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 16          350 0.001307698 -2782.620</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 17          360 0.001266073 -2934.008</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 18          370 0.001184449 -3172.273</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 19          380 0.001183570 -3147.455</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 20          390 0.001084006 -2975.564</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 21          400 0.001078607 -2891.118</span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res</span>, type <span class="op">=</span> <span class="st">"tune"</span><span class="op">)</span></span>
<span class="r-plt img"><img src="abessrpca-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">res</span>, type <span class="op">=</span> <span class="st">"loss"</span><span class="op">)</span></span>
<span class="r-plt img"><img src="abessrpca-2.png" alt="" width="700" height="433"></span>
<span class="r-in"><span class="co"># }</span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Jin Zhu, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Zezhi Wang, Borui Tang, Shiyun Lin, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.1.</p>
</div>

      </footer></div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: 'd32715b0e35635336aba6377dd751e21',
    indexName: 'abess',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script></body></html>

