<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Adaptive Best-Subset Selection via Splicing — abess.default • abess</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Adaptive Best-Subset Selection via Splicing — abess.default" />
<meta property="og:description" content="Adaptive best-subset selection for regression, 
binary classification and censored-response modeling 
in polynomial times." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/abess-guide.html">An Introduction to `abess`</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/Mamba413/abess/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Adaptive Best-Subset Selection via Splicing</h1>
    <small class="dont-index">Source: <a href='https://github.com/Mamba413/abess/blob/master/R/abess.R'><code>R/abess.R</code></a></small>
    <div class="hidden name"><code>abess.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Adaptive best-subset selection for regression, 
binary classification and censored-response modeling 
in polynomial times.</p>
    </div>

    <pre class="usage"><span class='co'># S3 method for default</span>
<span class='fu'>abess</span><span class='op'>(</span>
  <span class='va'>x</span>,
  <span class='va'>y</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"gaussian"</span>, <span class='st'>"binomial"</span>, <span class='st'>"poisson"</span>, <span class='st'>"cox"</span>, <span class='st'>"mgaussian"</span>, <span class='st'>"multinomial"</span><span class='op'>)</span>,
  tune.path <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"sequence"</span>, <span class='st'>"gsection"</span><span class='op'>)</span>,
  tune.type <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"gic"</span>, <span class='st'>"ebic"</span>, <span class='st'>"bic"</span>, <span class='st'>"aic"</span>, <span class='st'>"cv"</span><span class='op'>)</span>,
  weight <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span>,
  normalize <span class='op'>=</span> <span class='cn'>NULL</span>,
  c.max <span class='op'>=</span> <span class='fl'>2</span>,
  support.size <span class='op'>=</span> <span class='cn'>NULL</span>,
  gs.range <span class='op'>=</span> <span class='cn'>NULL</span>,
  always.include <span class='op'>=</span> <span class='cn'>NULL</span>,
  max.splicing.iter <span class='op'>=</span> <span class='fl'>20</span>,
  screening.num <span class='op'>=</span> <span class='cn'>NULL</span>,
  warm.start <span class='op'>=</span> <span class='cn'>TRUE</span>,
  nfolds <span class='op'>=</span> <span class='fl'>5</span>,
  cov.update <span class='op'>=</span> <span class='cn'>TRUE</span>,
  newton <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"exact"</span>, <span class='st'>"approx"</span><span class='op'>)</span>,
  newton.thresh <span class='op'>=</span> <span class='fl'>1e-06</span>,
  max.newton.iter <span class='op'>=</span> <span class='cn'>NULL</span>,
  early.stop <span class='op'>=</span> <span class='cn'>FALSE</span>,
  num.threads <span class='op'>=</span> <span class='fl'>0</span>,
  seed <span class='op'>=</span> <span class='fl'>1</span>,
  <span class='va'>...</span>
<span class='op'>)</span>

<span class='co'># S3 method for formula</span>
<span class='fu'>abess</span><span class='op'>(</span><span class='va'>formula</span>, <span class='va'>data</span>, <span class='va'>subset</span>, <span class='va'>na.action</span>, <span class='va'>...</span><span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>Input matrix, of dimension \(n \times p\); each row is an observation
vector and each column is a predictor/feature/variable.</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>The response variable, of <code>n</code> observations. 
For <code>family = "binomial"</code> should have two levels. 
For <code>family="poisson"</code>, <code>y</code> should be a vector with positive integer. 
For <code>family = "cox"</code>, <code>y</code> should be a two-column matrix with columns named <code>time</code> and <code>status</code>.
For <code>family = "mgaussian"</code>, <code>y</code> should be a matrix of quantitative responses.
For <code>family = "multinomial"</code>, <code>y</code> should be a factor of at least three levels.
Note that, for either <code>"binomial"</code> or <code>"multinomial"</code>, 
if y is presented as a numerical vector, it will be coerced into a factor.</p></td>
    </tr>
    <tr>
      <th>family</th>
      <td><p>One of the following models: 
<code>"gaussian"</code> (continuous response), 
<code>"binomial"</code> (binary response), 
<code>"poisson"</code> (non-negative count), 
<code>"cox"</code> (left-censored response), 
<code>"mgaussian"</code> (multivariate continuous response).
Depending on the response. Any unambiguous substring can be given.</p></td>
    </tr>
    <tr>
      <th>tune.path</th>
      <td><p>The method to be used to select the optimal support size. For
<code>method = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>method = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p></td>
    </tr>
    <tr>
      <th>tune.type</th>
      <td><p>The type of criterion for choosing the support size. 
Available options are <code>"gic"</code>, <code>"ebic"</code>, <code>"bic"</code>, <code>"aic"</code> and <code>"cv"</code>.
Default is <code>"gic"</code>.</p></td>
    </tr>
    <tr>
      <th>weight</th>
      <td><p>Observation weights. Default is <code>1</code> for each observation.</p></td>
    </tr>
    <tr>
      <th>normalize</th>
      <td><p>Options for normalization. <code>normalize = 0</code> for no normalization. 
<code>normalize = 1</code> for subtracting the mean of columns of <code>x</code>.
<code>normalize = 2</code> for scaling the columns of <code>x</code> to have \(\sqrt n\) norm.
<code>normalize = 3</code> for subtracting the means of the columns of <code>x</code> and <code>y</code>, and also
normalizing the columns of <code>x</code> to have \(\sqrt n\) norm.
If <code>normalize = NULL</code>, <code>normalize</code> will be set <code>1</code> for <code>"gaussian"</code>,
<code>2</code> for <code>"binomial"</code>. Default is <code>normalize = NULL</code>.</p></td>
    </tr>
    <tr>
      <th>c.max</th>
      <td><p>an integer splicing size. Default is: <code>c.max = 2</code>.</p></td>
    </tr>
    <tr>
      <th>support.size</th>
      <td><p>An integer vector representing the alternative support sizes. 
Only used for <code>method = "sequence"</code>. Default is <code>0:min(n, round(n/(log(log(n))log(p))))</code>.</p></td>
    </tr>
    <tr>
      <th>gs.range</th>
      <td><p>A integer vector with two elements. 
The first element is the minimum model size considered by golden-section, 
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.</p></td>
    </tr>
    <tr>
      <th>always.include</th>
      <td><p>An integer vector containing the indexes of variables that should always be included in the model.</p></td>
    </tr>
    <tr>
      <th>max.splicing.iter</th>
      <td><p>The maximum number of performing splicing algorithm. 
In most of the case, only a few times of splicing iteration can guarantee the convergence. 
Default is <code>max.splicing.iter = 20</code>.</p></td>
    </tr>
    <tr>
      <th>screening.num</th>
      <td><p>An integer number. Preserve <code>screening.num</code> number of predictors with the largest 
marginal maximum likelihood estimator before running algorithm.</p></td>
    </tr>
    <tr>
      <th>warm.start</th>
      <td><p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p></td>
    </tr>
    <tr>
      <th>nfolds</th>
      <td><p>The number of folds in cross-validation. Default is <code>nfolds = 5</code>.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code>. Default is <code>NULL</code>.</p></td>
    </tr>
    <tr>
      <th>cov.update</th>
      <td><p>A logical value only used for <code>family = "gaussian"</code>. If <code>cov.update = TRUE</code>, 
use a covariance-based implementation; otherwise, a naive implementation. 
The naive method is more efficient than covariance-based method only when \(p &gt;&gt; n\). 
Default: <code>cov.update = TRUE</code>.</p></td>
    </tr>
    <tr>
      <th>newton</th>
      <td><p>A character specify the Newton's method for fitting generalized linear models, 
it should be either <code>newton = "exact"</code> or <code>newton = "approx"</code>.
If <code>newton = "exact"</code>, then the exact hessian is used, 
while <code>newton = "approx"</code> uses diagonal entry of the hessian, 
and can be faster (especially when <code>family = "cox"</code>).</p></td>
    </tr>
    <tr>
      <th>newton.thresh</th>
      <td><p>a numerica value for controlling positive convergence tolerance. 
The Newton's iterations converge when \(|dev - dev_{old}|/(|dev| + 0.1)&lt;\) <code>newton.thresh</code>.</p></td>
    </tr>
    <tr>
      <th>max.newton.iter</th>
      <td><p>a integer giving the maximal number of Newton's iteration iterations.
Default is <code>max.newton.iter = 10</code> if <code>newton = "exact"</code>, and <code>max.newton.iter = 60</code> if <code>newton = "approx"</code>.</p></td>
    </tr>
    <tr>
      <th>early.stop</th>
      <td><p>A boolean value decide whether early stoping. 
If <code>early.stop = TRUE</code>, algorithm will stop if the last tuning value less than the existing one. 
Default: <code>early.stop = FALSE</code>.</p></td>
    </tr>
    <tr>
      <th>num.threads</th>
      <td><p>An integer decide the number of threads to be 
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>). 
If <code>num.threads = 0</code>, then all of available cores will be used. 
Default: <code>num.threads = 0</code>.</p></td>
    </tr>
    <tr>
      <th>seed</th>
      <td><p>Seed to be used to divide the sample into cross-validation folds. 
Default is <code>seed = 1</code>.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>further arguments to be passed to or from methods.</p></td>
    </tr>
    <tr>
      <th>formula</th>
      <td><p>an object of class "<code>formula</code>": 
a symbolic description of the model to be fitted. 
The details of model specification are given in the "Details" section of "<code><a href='https://rdrr.io/r/stats/formula.html'>formula</a></code>".</p></td>
    </tr>
    <tr>
      <th>data</th>
      <td><p>a data frame containing the variables in the <code>formula</code>.</p></td>
    </tr>
    <tr>
      <th>subset</th>
      <td><p>an optional vector specifying a subset of observations to be used.</p></td>
    </tr>
    <tr>
      <th>na.action</th>
      <td><p>a function which indicates 
what should happen when the data contain <code>NA</code>s. 
Defaults to <code><a href='https://rdrr.io/r/base/options.html'>getOption("na.action")</a></code>.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A <code>abess</code> class object, which is a <code>list</code> with the following components:</p>
<dt>beta</dt><dd><p>A \(p\)-by-<code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> matrix of coefficients for univariate family, stored in column format;
while a list of <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> coefficients matrix (with size \(p\)-by-<code><a href='https://rdrr.io/r/base/nrow.html'>ncol(y)</a></code>) for multivariate family.</p></dd>
<dt>intercept</dt><dd><p>An intercept vector of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> for univariate family; 
while a list of <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> intercept vector (with size <code><a href='https://rdrr.io/r/base/nrow.html'>ncol(y)</a></code>) for multivariate family.</p></dd>
<dt>dev</dt><dd><p>the deviance of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code>.</p></dd>
<dt>tune.value</dt><dd><p>A value of tuning criterion of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code>.</p></dd>
<dt>nobs</dt><dd><p>The number of sample used for training.</p></dd>
<dt>nvars</dt><dd><p>The number of variables used for training.</p></dd>
<dt>family</dt><dd><p>Type of the model.</p></dd>
<dt>tune.path</dt><dd><p>The path type for tuning parameters.</p></dd>
<dt>support.size</dt><dd><p>The actual <code>support.size</code> values used. 
Note that it is not necessary the same as the input 
if the later have non-integer values or duplicated values.</p></dd>
<dt>best.size</dt><dd><p>The best support size selected by the tuning value.</p></dd> 
<dt>tune.type</dt><dd><p>The criterion type for tuning parameters.</p></dd>
<dt>tune.path</dt><dd><p>The strategy for tuning parameters.</p></dd>
<dt>screening.vars</dt><dd><p>The character vector specify the feature 
selected by feature screening. 
It would a empty character vector if <code>screening.num = 0</code>.</p></dd>
<dt>call</dt><dd><p>The original call to <code>abess</code>.</p></dd>

    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; DOI: 10.1073/pnas.2014241117</p>
<p>Sure independence screening for ultrahigh dimensional feature space. Fan, J. and Lv, J. (2008), Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70: 849-911. https://doi.org/10.1111/j.1467-9868.2008.00674.x</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='print.abess.html'>print.abess</a></code>, 
<code><a href='predict.abess.html'>predict.abess</a></code>, 
<code><a href='coef.abess.html'>coef.abess</a></code>, 
<code><a href='extract.html'>extract.abess</a></code>,
<code><a href='deviance.abess.html'>deviance.abess</a></code>.</p></div>
    <h2 class="hasAnchor" id="author"><a class="anchor" href="#author"></a>Author</h2>

    <p>Jin Zhu, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fl'>100</span>
<span class='va'>p</span> <span class='op'>&lt;-</span> <span class='fl'>20</span>
<span class='va'>support.size</span> <span class='op'>&lt;-</span> <span class='fl'>3</span>

<span class='co'>################ linear model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='co'>## helpful generic functions:</span>
<span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]])
#&gt; 
#&gt;    support.size       dev      GIC
#&gt; 1             0 17805.684 978.7273
#&gt; 2             1 10163.270 927.2286
#&gt; 3             2  4407.395 848.2540
#&gt; 4             3  1842.745 765.6262
#&gt; 5             4  1667.015 760.1791
#&gt; 6             5  1594.016 760.2763
#&gt; 7             6  1543.874 761.6551
#&gt; 8             7  1518.615 764.5805
#&gt; 9             8  1500.112 767.9297
#&gt; 10            9  1486.034 771.5618
#&gt; 11           10  1473.749 775.3067
#&gt; 12           11  1460.411 778.9725
#&gt; 13           12  1452.290 782.9899
#&gt; 14           13  1444.224 787.0080
#&gt; 15           14  1439.776 791.2745
#&gt; 16           15  1437.522 795.6929
#&gt; 17           16  1435.833 800.1504
#&gt; 18           17  1434.539 804.6352
#&gt; 19           18  1433.386 809.1298
#&gt; 20           19  1432.351 813.6327
#&gt; 21           20  1432.225 813.6239</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/coef.html'>coef</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, support.size <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"
#&gt;                     3
#&gt; (intercept) -4.369861
#&gt; x1           .       
#&gt; x2           .       
#&gt; x3           .       
#&gt; x4           .       
#&gt; x5           .       
#&gt; x6          83.270800
#&gt; x7           .       
#&gt; x8           .       
#&gt; x9           .       
#&gt; x10          .       
#&gt; x11          .       
#&gt; x12          .       
#&gt; x13          .       
#&gt; x14         89.689944
#&gt; x15          .       
#&gt; x16          .       
#&gt; x17          .       
#&gt; x18         43.410846
#&gt; x19          .       
#&gt; x20          .       </div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, newx <span class='op'>=</span> <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>, <span class='op'>]</span>, 
        support.size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>4</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt;                3           4
#&gt;  [1,]  103.05157   91.524774
#&gt;  [2,]   74.66998   85.359664
#&gt;  [3,] -289.97309 -299.858907
#&gt;  [4,]  -16.35758   -4.241221
#&gt;  [5,]  171.80572  162.807112
#&gt;  [6,]  126.58540  127.021354
#&gt;  [7,] -197.24366 -207.134508
#&gt;  [8,] -126.67823 -142.927367
#&gt;  [9,]  -23.29128  -22.898065
#&gt; [10,] -109.76937 -117.273626</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 7
#&gt;  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
#&gt;   .. ..@ i       : int [1:4] 5 13 15 17
#&gt;   .. ..@ p       : int [1:2] 0 4
#&gt;   .. ..@ Dim     : int [1:2] 20 1
#&gt;   .. ..@ Dimnames:List of 2
#&gt;   .. .. ..$ : chr [1:20] "x1" "x2" "x3" "x4" ...
#&gt;   .. .. ..$ : chr "4"
#&gt;   .. ..@ x       : num [1:4] 82.4 89 -12.6 43.3
#&gt;   .. ..@ factors : list()
#&gt;  $ intercept   : num -4.77
#&gt;  $ support.size: int 4
#&gt;  $ support.vars: chr [1:4] "x6" "x14" "x16" "x18"
#&gt;  $ support.beta: num [1:4] 82.4 89 -12.6 43.3
#&gt;  $ dev         : num 1667
#&gt;  $ tune.value  : num 760</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/deviance.html'>deviance</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='output co'>#&gt;  [1] 17805.684 10163.270  4407.395  1842.745  1667.015  1594.016  1543.874
#&gt;  [8]  1518.615  1500.112  1486.034  1473.749  1460.411  1452.290  1444.224
#&gt; [15]  1439.776  1437.522  1435.833  1434.539  1433.386  1432.351  1432.225</div><div class='input'>
<span class='co'>################ logistic model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>
<span class='co'>## allow cross-validation to tuning</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"binomial"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]], family = "binomial", 
#&gt;     tune.type = "cv")
#&gt; 
#&gt;    support.size       dev        cv
#&gt; 1             0  68.59298 13.888785
#&gt; 2             1  46.69364  9.467560
#&gt; 3             2  22.31417  4.795569
#&gt; 4             3  17.60334  5.453128
#&gt; 5             4  16.86618  9.348024
#&gt; 6             5  16.06971 14.488638
#&gt; 7             6  15.26069 22.724323
#&gt; 8             7  14.18543 33.229924
#&gt; 9             8  12.91200 42.426394
#&gt; 10            9  11.00353 56.632611
#&gt; 11           10  10.04500 61.999518
#&gt; 12           11  10.18355 66.914255
#&gt; 13           12 173.00172 71.793735
#&gt; 14           13 142.19030 80.653895
#&gt; 15           14  88.00513 80.122038
#&gt; 16           15 122.44452 82.172393
#&gt; 17           16 141.91677 83.516764
#&gt; 18           17 105.22047 83.446261
#&gt; 19           18 109.50414 83.731671
#&gt; 20           19 113.17618 84.137978
#&gt; 21           20 154.73864 84.729315</div><div class='input'>
<span class='co'>################ Cox model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"cox"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; censoring rate: 0.57 </div><div class='input'><span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"cox"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span>, 
                   newton <span class='op'>=</span> <span class='st'>"approx"</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]], family = "cox", 
#&gt;     tune.type = "cv", newton = "approx")
#&gt; 
#&gt;    support.size      dev       cv
#&gt; 1             0 186.9720 23.45101
#&gt; 2             1 167.3854 20.53945
#&gt; 3             2 142.9906 15.15529
#&gt; 4             3 122.6477 12.43033
#&gt; 5             4 119.1235 13.22219
#&gt; 6             5 117.8076 13.72121
#&gt; 7             6 116.9300 14.42269
#&gt; 8             7 116.4218 14.29653
#&gt; 9             8 115.2787 15.01824
#&gt; 10            9 114.9203 15.39002
#&gt; 11           10 114.5888 17.09378
#&gt; 12           11 114.3221 18.53581
#&gt; 13           12 114.2761 20.64661
#&gt; 14           13 114.0693 21.82383
#&gt; 15           14 113.9716 22.32343
#&gt; 16           15 113.8485 21.99663
#&gt; 17           16 113.7331 22.42952
#&gt; 18           17 113.6946 22.48710
#&gt; 19           18 113.6652 22.72920
#&gt; 20           19 113.6552 22.69666
#&gt; 21           20 113.6537 22.65670</div><div class='input'>
<span class='co'>################ Feature screening ################</span>
<span class='va'>p</span> <span class='op'>&lt;-</span> <span class='fl'>1000</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   screening.num <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>
<span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='output co'>#&gt; $beta
#&gt; 1000 x 1 sparse Matrix of class "dgCMatrix"
#&gt;       0
#&gt; x1    .
#&gt; x2    .
#&gt; x3    .
#&gt; x4    .
#&gt; x5    .
#&gt; x6    .
#&gt; x7    .
#&gt; x8    .
#&gt; x9    .
#&gt; x10   .
#&gt; x11   .
#&gt; x12   .
#&gt; x13   .
#&gt; x14   .
#&gt; x15   .
#&gt; x16   .
#&gt; x17   .
#&gt; x18   .
#&gt; x19   .
#&gt; x20   .
#&gt; x21   .
#&gt; x22   .
#&gt; x23   .
#&gt; x24   .
#&gt; x25   .
#&gt; x26   .
#&gt; x27   .
#&gt; x28   .
#&gt; x29   .
#&gt; x30   .
#&gt; x31   .
#&gt; x32   .
#&gt; x33   .
#&gt; x34   .
#&gt; x35   .
#&gt; x36   .
#&gt; x37   .
#&gt; x38   .
#&gt; x39   .
#&gt; x40   .
#&gt; x41   .
#&gt; x42   .
#&gt; x43   .
#&gt; x44   .
#&gt; x45   .
#&gt; x46   .
#&gt; x47   .
#&gt; x48   .
#&gt; x49   .
#&gt; x50   .
#&gt; x51   .
#&gt; x52   .
#&gt; x53   .
#&gt; x54   .
#&gt; x55   .
#&gt; x56   .
#&gt; x57   .
#&gt; x58   .
#&gt; x59   .
#&gt; x60   .
#&gt; x61   .
#&gt; x62   .
#&gt; x63   .
#&gt; x64   .
#&gt; x65   .
#&gt; x66   .
#&gt; x67   .
#&gt; x68   .
#&gt; x69   .
#&gt; x70   .
#&gt; x71   .
#&gt; x72   .
#&gt; x73   .
#&gt; x74   .
#&gt; x75   .
#&gt; x76   .
#&gt; x77   .
#&gt; x78   .
#&gt; x79   .
#&gt; x80   .
#&gt; x81   .
#&gt; x82   .
#&gt; x83   .
#&gt; x84   .
#&gt; x85   .
#&gt; x86   .
#&gt; x87   .
#&gt; x88   .
#&gt; x89   .
#&gt; x90   .
#&gt; x91   .
#&gt; x92   .
#&gt; x93   .
#&gt; x94   .
#&gt; x95   .
#&gt; x96   .
#&gt; x97   .
#&gt; x98   .
#&gt; x99   .
#&gt; x100  .
#&gt; x101  .
#&gt; x102  .
#&gt; x103  .
#&gt; x104  .
#&gt; x105  .
#&gt; x106  .
#&gt; x107  .
#&gt; x108  .
#&gt; x109  .
#&gt; x110  .
#&gt; x111  .
#&gt; x112  .
#&gt; x113  .
#&gt; x114  .
#&gt; x115  .
#&gt; x116  .
#&gt; x117  .
#&gt; x118  .
#&gt; x119  .
#&gt; x120  .
#&gt; x121  .
#&gt; x122  .
#&gt; x123  .
#&gt; x124  .
#&gt; x125  .
#&gt; x126  .
#&gt; x127  .
#&gt; x128  .
#&gt; x129  .
#&gt; x130  .
#&gt; x131  .
#&gt; x132  .
#&gt; x133  .
#&gt; x134  .
#&gt; x135  .
#&gt; x136  .
#&gt; x137  .
#&gt; x138  .
#&gt; x139  .
#&gt; x140  .
#&gt; x141  .
#&gt; x142  .
#&gt; x143  .
#&gt; x144  .
#&gt; x145  .
#&gt; x146  .
#&gt; x147  .
#&gt; x148  .
#&gt; x149  .
#&gt; x150  .
#&gt; x151  .
#&gt; x152  .
#&gt; x153  .
#&gt; x154  .
#&gt; x155  .
#&gt; x156  .
#&gt; x157  .
#&gt; x158  .
#&gt; x159  .
#&gt; x160  .
#&gt; x161  .
#&gt; x162  .
#&gt; x163  .
#&gt; x164  .
#&gt; x165  .
#&gt; x166  .
#&gt; x167  .
#&gt; x168  .
#&gt; x169  .
#&gt; x170  .
#&gt; x171  .
#&gt; x172  .
#&gt; x173  .
#&gt; x174  .
#&gt; x175  .
#&gt; x176  .
#&gt; x177  .
#&gt; x178  .
#&gt; x179  .
#&gt; x180  .
#&gt; x181  .
#&gt; x182  .
#&gt; x183  .
#&gt; x184  .
#&gt; x185  .
#&gt; x186  .
#&gt; x187  .
#&gt; x188  .
#&gt; x189  .
#&gt; x190  .
#&gt; x191  .
#&gt; x192  .
#&gt; x193  .
#&gt; x194  .
#&gt; x195  .
#&gt; x196  .
#&gt; x197  .
#&gt; x198  .
#&gt; x199  .
#&gt; x200  .
#&gt; x201  .
#&gt; x202  .
#&gt; x203  .
#&gt; x204  .
#&gt; x205  .
#&gt; x206  .
#&gt; x207  .
#&gt; x208  .
#&gt; x209  .
#&gt; x210  .
#&gt; x211  .
#&gt; x212  .
#&gt; x213  .
#&gt; x214  .
#&gt; x215  .
#&gt; x216  .
#&gt; x217  .
#&gt; x218  .
#&gt; x219  .
#&gt; x220  .
#&gt; x221  .
#&gt; x222  .
#&gt; x223  .
#&gt; x224  .
#&gt; x225  .
#&gt; x226  .
#&gt; x227  .
#&gt; x228  .
#&gt; x229  .
#&gt; x230  .
#&gt; x231  .
#&gt; x232  .
#&gt; x233  .
#&gt; x234  .
#&gt; x235  .
#&gt; x236  .
#&gt; x237  .
#&gt; x238  .
#&gt; x239  .
#&gt; x240  .
#&gt; x241  .
#&gt; x242  .
#&gt; x243  .
#&gt; x244  .
#&gt; x245  .
#&gt; x246  .
#&gt; x247  .
#&gt; x248  .
#&gt; x249  .
#&gt; x250  .
#&gt; x251  .
#&gt; x252  .
#&gt; x253  .
#&gt; x254  .
#&gt; x255  .
#&gt; x256  .
#&gt; x257  .
#&gt; x258  .
#&gt; x259  .
#&gt; x260  .
#&gt; x261  .
#&gt; x262  .
#&gt; x263  .
#&gt; x264  .
#&gt; x265  .
#&gt; x266  .
#&gt; x267  .
#&gt; x268  .
#&gt; x269  .
#&gt; x270  .
#&gt; x271  .
#&gt; x272  .
#&gt; x273  .
#&gt; x274  .
#&gt; x275  .
#&gt; x276  .
#&gt; x277  .
#&gt; x278  .
#&gt; x279  .
#&gt; x280  .
#&gt; x281  .
#&gt; x282  .
#&gt; x283  .
#&gt; x284  .
#&gt; x285  .
#&gt; x286  .
#&gt; x287  .
#&gt; x288  .
#&gt; x289  .
#&gt; x290  .
#&gt; x291  .
#&gt; x292  .
#&gt; x293  .
#&gt; x294  .
#&gt; x295  .
#&gt; x296  .
#&gt; x297  .
#&gt; x298  .
#&gt; x299  .
#&gt; x300  .
#&gt; x301  .
#&gt; x302  .
#&gt; x303  .
#&gt; x304  .
#&gt; x305  .
#&gt; x306  .
#&gt; x307  .
#&gt; x308  .
#&gt; x309  .
#&gt; x310  .
#&gt; x311  .
#&gt; x312  .
#&gt; x313  .
#&gt; x314  .
#&gt; x315  .
#&gt; x316  .
#&gt; x317  .
#&gt; x318  .
#&gt; x319  .
#&gt; x320  .
#&gt; x321  .
#&gt; x322  .
#&gt; x323  .
#&gt; x324  .
#&gt; x325  .
#&gt; x326  .
#&gt; x327  .
#&gt; x328  .
#&gt; x329  .
#&gt; x330  .
#&gt; x331  .
#&gt; x332  .
#&gt; x333  .
#&gt; x334  .
#&gt; x335  .
#&gt; x336  .
#&gt; x337  .
#&gt; x338  .
#&gt; x339  .
#&gt; x340  .
#&gt; x341  .
#&gt; x342  .
#&gt; x343  .
#&gt; x344  .
#&gt; x345  .
#&gt; x346  .
#&gt; x347  .
#&gt; x348  .
#&gt; x349  .
#&gt; x350  .
#&gt; x351  .
#&gt; x352  .
#&gt; x353  .
#&gt; x354  .
#&gt; x355  .
#&gt; x356  .
#&gt; x357  .
#&gt; x358  .
#&gt; x359  .
#&gt; x360  .
#&gt; x361  .
#&gt; x362  .
#&gt; x363  .
#&gt; x364  .
#&gt; x365  .
#&gt; x366  .
#&gt; x367  .
#&gt; x368  .
#&gt; x369  .
#&gt; x370  .
#&gt; x371  .
#&gt; x372  .
#&gt; x373  .
#&gt; x374  .
#&gt; x375  .
#&gt; x376  .
#&gt; x377  .
#&gt; x378  .
#&gt; x379  .
#&gt; x380  .
#&gt; x381  .
#&gt; x382  .
#&gt; x383  .
#&gt; x384  .
#&gt; x385  .
#&gt; x386  .
#&gt; x387  .
#&gt; x388  .
#&gt; x389  .
#&gt; x390  .
#&gt; x391  .
#&gt; x392  .
#&gt; x393  .
#&gt; x394  .
#&gt; x395  .
#&gt; x396  .
#&gt; x397  .
#&gt; x398  .
#&gt; x399  .
#&gt; x400  .
#&gt; x401  .
#&gt; x402  .
#&gt; x403  .
#&gt; x404  .
#&gt; x405  .
#&gt; x406  .
#&gt; x407  .
#&gt; x408  .
#&gt; x409  .
#&gt; x410  .
#&gt; x411  .
#&gt; x412  .
#&gt; x413  .
#&gt; x414  .
#&gt; x415  .
#&gt; x416  .
#&gt; x417  .
#&gt; x418  .
#&gt; x419  .
#&gt; x420  .
#&gt; x421  .
#&gt; x422  .
#&gt; x423  .
#&gt; x424  .
#&gt; x425  .
#&gt; x426  .
#&gt; x427  .
#&gt; x428  .
#&gt; x429  .
#&gt; x430  .
#&gt; x431  .
#&gt; x432  .
#&gt; x433  .
#&gt; x434  .
#&gt; x435  .
#&gt; x436  .
#&gt; x437  .
#&gt; x438  .
#&gt; x439  .
#&gt; x440  .
#&gt; x441  .
#&gt; x442  .
#&gt; x443  .
#&gt; x444  .
#&gt; x445  .
#&gt; x446  .
#&gt; x447  .
#&gt; x448  .
#&gt; x449  .
#&gt; x450  .
#&gt; x451  .
#&gt; x452  .
#&gt; x453  .
#&gt; x454  .
#&gt; x455  .
#&gt; x456  .
#&gt; x457  .
#&gt; x458  .
#&gt; x459  .
#&gt; x460  .
#&gt; x461  .
#&gt; x462  .
#&gt; x463  .
#&gt; x464  .
#&gt; x465  .
#&gt; x466  .
#&gt; x467  .
#&gt; x468  .
#&gt; x469  .
#&gt; x470  .
#&gt; x471  .
#&gt; x472  .
#&gt; x473  .
#&gt; x474  .
#&gt; x475  .
#&gt; x476  .
#&gt; x477  .
#&gt; x478  .
#&gt; x479  .
#&gt; x480  .
#&gt; x481  .
#&gt; x482  .
#&gt; x483  .
#&gt; x484  .
#&gt; x485  .
#&gt; x486  .
#&gt; x487  .
#&gt; x488  .
#&gt; x489  .
#&gt; x490  .
#&gt; x491  .
#&gt; x492  .
#&gt; x493  .
#&gt; x494  .
#&gt; x495  .
#&gt; x496  .
#&gt; x497  .
#&gt; x498  .
#&gt; x499  .
#&gt; x500  .
#&gt; x501  .
#&gt; x502  .
#&gt; x503  .
#&gt; x504  .
#&gt; x505  .
#&gt; x506  .
#&gt; x507  .
#&gt; x508  .
#&gt; x509  .
#&gt; x510  .
#&gt; x511  .
#&gt; x512  .
#&gt; x513  .
#&gt; x514  .
#&gt; x515  .
#&gt; x516  .
#&gt; x517  .
#&gt; x518  .
#&gt; x519  .
#&gt; x520  .
#&gt; x521  .
#&gt; x522  .
#&gt; x523  .
#&gt; x524  .
#&gt; x525  .
#&gt; x526  .
#&gt; x527  .
#&gt; x528  .
#&gt; x529  .
#&gt; x530  .
#&gt; x531  .
#&gt; x532  .
#&gt; x533  .
#&gt; x534  .
#&gt; x535  .
#&gt; x536  .
#&gt; x537  .
#&gt; x538  .
#&gt; x539  .
#&gt; x540  .
#&gt; x541  .
#&gt; x542  .
#&gt; x543  .
#&gt; x544  .
#&gt; x545  .
#&gt; x546  .
#&gt; x547  .
#&gt; x548  .
#&gt; x549  .
#&gt; x550  .
#&gt; x551  .
#&gt; x552  .
#&gt; x553  .
#&gt; x554  .
#&gt; x555  .
#&gt; x556  .
#&gt; x557  .
#&gt; x558  .
#&gt; x559  .
#&gt; x560  .
#&gt; x561  .
#&gt; x562  .
#&gt; x563  .
#&gt; x564  .
#&gt; x565  .
#&gt; x566  .
#&gt; x567  .
#&gt; x568  .
#&gt; x569  .
#&gt; x570  .
#&gt; x571  .
#&gt; x572  .
#&gt; x573  .
#&gt; x574  .
#&gt; x575  .
#&gt; x576  .
#&gt; x577  .
#&gt; x578  .
#&gt; x579  .
#&gt; x580  .
#&gt; x581  .
#&gt; x582  .
#&gt; x583  .
#&gt; x584  .
#&gt; x585  .
#&gt; x586  .
#&gt; x587  .
#&gt; x588  .
#&gt; x589  .
#&gt; x590  .
#&gt; x591  .
#&gt; x592  .
#&gt; x593  .
#&gt; x594  .
#&gt; x595  .
#&gt; x596  .
#&gt; x597  .
#&gt; x598  .
#&gt; x599  .
#&gt; x600  .
#&gt; x601  .
#&gt; x602  .
#&gt; x603  .
#&gt; x604  .
#&gt; x605  .
#&gt; x606  .
#&gt; x607  .
#&gt; x608  .
#&gt; x609  .
#&gt; x610  .
#&gt; x611  .
#&gt; x612  .
#&gt; x613  .
#&gt; x614  .
#&gt; x615  .
#&gt; x616  .
#&gt; x617  .
#&gt; x618  .
#&gt; x619  .
#&gt; x620  .
#&gt; x621  .
#&gt; x622  .
#&gt; x623  .
#&gt; x624  .
#&gt; x625  .
#&gt; x626  .
#&gt; x627  .
#&gt; x628  .
#&gt; x629  .
#&gt; x630  .
#&gt; x631  .
#&gt; x632  .
#&gt; x633  .
#&gt; x634  .
#&gt; x635  .
#&gt; x636  .
#&gt; x637  .
#&gt; x638  .
#&gt; x639  .
#&gt; x640  .
#&gt; x641  .
#&gt; x642  .
#&gt; x643  .
#&gt; x644  .
#&gt; x645  .
#&gt; x646  .
#&gt; x647  .
#&gt; x648  .
#&gt; x649  .
#&gt; x650  .
#&gt; x651  .
#&gt; x652  .
#&gt; x653  .
#&gt; x654  .
#&gt; x655  .
#&gt; x656  .
#&gt; x657  .
#&gt; x658  .
#&gt; x659  .
#&gt; x660  .
#&gt; x661  .
#&gt; x662  .
#&gt; x663  .
#&gt; x664  .
#&gt; x665  .
#&gt; x666  .
#&gt; x667  .
#&gt; x668  .
#&gt; x669  .
#&gt; x670  .
#&gt; x671  .
#&gt; x672  .
#&gt; x673  .
#&gt; x674  .
#&gt; x675  .
#&gt; x676  .
#&gt; x677  .
#&gt; x678  .
#&gt; x679  .
#&gt; x680  .
#&gt; x681  .
#&gt; x682  .
#&gt; x683  .
#&gt; x684  .
#&gt; x685  .
#&gt; x686  .
#&gt; x687  .
#&gt; x688  .
#&gt; x689  .
#&gt; x690  .
#&gt; x691  .
#&gt; x692  .
#&gt; x693  .
#&gt; x694  .
#&gt; x695  .
#&gt; x696  .
#&gt; x697  .
#&gt; x698  .
#&gt; x699  .
#&gt; x700  .
#&gt; x701  .
#&gt; x702  .
#&gt; x703  .
#&gt; x704  .
#&gt; x705  .
#&gt; x706  .
#&gt; x707  .
#&gt; x708  .
#&gt; x709  .
#&gt; x710  .
#&gt; x711  .
#&gt; x712  .
#&gt; x713  .
#&gt; x714  .
#&gt; x715  .
#&gt; x716  .
#&gt; x717  .
#&gt; x718  .
#&gt; x719  .
#&gt; x720  .
#&gt; x721  .
#&gt; x722  .
#&gt; x723  .
#&gt; x724  .
#&gt; x725  .
#&gt; x726  .
#&gt; x727  .
#&gt; x728  .
#&gt; x729  .
#&gt; x730  .
#&gt; x731  .
#&gt; x732  .
#&gt; x733  .
#&gt; x734  .
#&gt; x735  .
#&gt; x736  .
#&gt; x737  .
#&gt; x738  .
#&gt; x739  .
#&gt; x740  .
#&gt; x741  .
#&gt; x742  .
#&gt; x743  .
#&gt; x744  .
#&gt; x745  .
#&gt; x746  .
#&gt; x747  .
#&gt; x748  .
#&gt; x749  .
#&gt; x750  .
#&gt; x751  .
#&gt; x752  .
#&gt; x753  .
#&gt; x754  .
#&gt; x755  .
#&gt; x756  .
#&gt; x757  .
#&gt; x758  .
#&gt; x759  .
#&gt; x760  .
#&gt; x761  .
#&gt; x762  .
#&gt; x763  .
#&gt; x764  .
#&gt; x765  .
#&gt; x766  .
#&gt; x767  .
#&gt; x768  .
#&gt; x769  .
#&gt; x770  .
#&gt; x771  .
#&gt; x772  .
#&gt; x773  .
#&gt; x774  .
#&gt; x775  .
#&gt; x776  .
#&gt; x777  .
#&gt; x778  .
#&gt; x779  .
#&gt; x780  .
#&gt; x781  .
#&gt; x782  .
#&gt; x783  .
#&gt; x784  .
#&gt; x785  .
#&gt; x786  .
#&gt; x787  .
#&gt; x788  .
#&gt; x789  .
#&gt; x790  .
#&gt; x791  .
#&gt; x792  .
#&gt; x793  .
#&gt; x794  .
#&gt; x795  .
#&gt; x796  .
#&gt; x797  .
#&gt; x798  .
#&gt; x799  .
#&gt; x800  .
#&gt; x801  .
#&gt; x802  .
#&gt; x803  .
#&gt; x804  .
#&gt; x805  .
#&gt; x806  .
#&gt; x807  .
#&gt; x808  .
#&gt; x809  .
#&gt; x810  .
#&gt; x811  .
#&gt; x812  .
#&gt; x813  .
#&gt; x814  .
#&gt; x815  .
#&gt; x816  .
#&gt; x817  .
#&gt; x818  .
#&gt; x819  .
#&gt; x820  .
#&gt; x821  .
#&gt; x822  .
#&gt; x823  .
#&gt; x824  .
#&gt; x825  .
#&gt; x826  .
#&gt; x827  .
#&gt; x828  .
#&gt; x829  .
#&gt; x830  .
#&gt; x831  .
#&gt; x832  .
#&gt; x833  .
#&gt; x834  .
#&gt; x835  .
#&gt; x836  .
#&gt; x837  .
#&gt; x838  .
#&gt; x839  .
#&gt; x840  .
#&gt; x841  .
#&gt; x842  .
#&gt; x843  .
#&gt; x844  .
#&gt; x845  .
#&gt; x846  .
#&gt; x847  .
#&gt; x848  .
#&gt; x849  .
#&gt; x850  .
#&gt; x851  .
#&gt; x852  .
#&gt; x853  .
#&gt; x854  .
#&gt; x855  .
#&gt; x856  .
#&gt; x857  .
#&gt; x858  .
#&gt; x859  .
#&gt; x860  .
#&gt; x861  .
#&gt; x862  .
#&gt; x863  .
#&gt; x864  .
#&gt; x865  .
#&gt; x866  .
#&gt; x867  .
#&gt; x868  .
#&gt; x869  .
#&gt; x870  .
#&gt; x871  .
#&gt; x872  .
#&gt; x873  .
#&gt; x874  .
#&gt; x875  .
#&gt; x876  .
#&gt; x877  .
#&gt; x878  .
#&gt; x879  .
#&gt; x880  .
#&gt; x881  .
#&gt; x882  .
#&gt; x883  .
#&gt; x884  .
#&gt; x885  .
#&gt; x886  .
#&gt; x887  .
#&gt; x888  .
#&gt; x889  .
#&gt; x890  .
#&gt; x891  .
#&gt; x892  .
#&gt; x893  .
#&gt; x894  .
#&gt; x895  .
#&gt; x896  .
#&gt; x897  .
#&gt; x898  .
#&gt; x899  .
#&gt; x900  .
#&gt; x901  .
#&gt; x902  .
#&gt; x903  .
#&gt; x904  .
#&gt; x905  .
#&gt; x906  .
#&gt; x907  .
#&gt; x908  .
#&gt; x909  .
#&gt; x910  .
#&gt; x911  .
#&gt; x912  .
#&gt; x913  .
#&gt; x914  .
#&gt; x915  .
#&gt; x916  .
#&gt; x917  .
#&gt; x918  .
#&gt; x919  .
#&gt; x920  .
#&gt; x921  .
#&gt; x922  .
#&gt; x923  .
#&gt; x924  .
#&gt; x925  .
#&gt; x926  .
#&gt; x927  .
#&gt; x928  .
#&gt; x929  .
#&gt; x930  .
#&gt; x931  .
#&gt; x932  .
#&gt; x933  .
#&gt; x934  .
#&gt; x935  .
#&gt; x936  .
#&gt; x937  .
#&gt; x938  .
#&gt; x939  .
#&gt; x940  .
#&gt; x941  .
#&gt; x942  .
#&gt; x943  .
#&gt; x944  .
#&gt; x945  .
#&gt; x946  .
#&gt; x947  .
#&gt; x948  .
#&gt; x949  .
#&gt; x950  .
#&gt; x951  .
#&gt; x952  .
#&gt; x953  .
#&gt; x954  .
#&gt; x955  .
#&gt; x956  .
#&gt; x957  .
#&gt; x958  .
#&gt; x959  .
#&gt; x960  .
#&gt; x961  .
#&gt; x962  .
#&gt; x963  .
#&gt; x964  .
#&gt; x965  .
#&gt; x966  .
#&gt; x967  .
#&gt; x968  .
#&gt; x969  .
#&gt; x970  .
#&gt; x971  .
#&gt; x972  .
#&gt; x973  .
#&gt; x974  .
#&gt; x975  .
#&gt; x976  .
#&gt; x977  .
#&gt; x978  .
#&gt; x979  .
#&gt; x980  .
#&gt; x981  .
#&gt; x982  .
#&gt; x983  .
#&gt; x984  .
#&gt; x985  .
#&gt; x986  .
#&gt; x987  .
#&gt; x988  .
#&gt; x989  .
#&gt; x990  .
#&gt; x991  .
#&gt; x992  .
#&gt; x993  .
#&gt; x994  .
#&gt; x995  .
#&gt; x996  .
#&gt; x997  .
#&gt; x998  .
#&gt; x999  .
#&gt; x1000 .
#&gt; 
#&gt; $intercept
#&gt; [1] -51.30934
#&gt; 
#&gt; $support.size
#&gt; [1] 0
#&gt; 
#&gt; $support.vars
#&gt; character(0)
#&gt; 
#&gt; $support.beta
#&gt; numeric(0)
#&gt; 
#&gt; $dev
#&gt; [1] 61176.56
#&gt; 
#&gt; $tune.value
#&gt; [1] 1102.152
#&gt; </div><div class='input'>
<span class='co'>################  Formula interface  ################</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='st'>"trim32"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>y</span> <span class='op'>~</span> <span class='va'>.</span>, data <span class='op'>=</span> <span class='va'>trim32</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.formula(formula = y ~ ., data = trim32)
#&gt; 
#&gt;    support.size         dev       GIC
#&gt; 1             0 0.020738622 -465.0909
#&gt; 2             1 0.008176953 -567.0402
#&gt; 3             2 0.006186442 -590.7832
#&gt; 4             3 0.004791180 -611.7211
#&gt; 5             4 0.004418203 -611.7142
#&gt; 6             5 0.003928650 -616.0745
#&gt; 7             6 0.003616324 -616.2830
#&gt; 8             7 0.003363741 -615.2394
#&gt; 9             8 0.003169559 -612.6426
#&gt; 10            9 0.002856742 -615.3798
#&gt; 11           10 0.002594231 -617.2147
#&gt; 12           11 0.002375152 -618.0700
#&gt; 13           12 0.002274280 -613.5456</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Jin Zhu, Kangkang Jiang, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


