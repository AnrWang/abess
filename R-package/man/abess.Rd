% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/abess.R
\name{abess}
\alias{abess}
\alias{abess.default}
\alias{abess.formula}
\title{Adaptive Best-Subset Selection via splicing algorithm}
\usage{
abess(x, ...)

\method{abess}{default}(
  x,
  y,
  family = c("gaussian", "binomial"),
  method = c("sequential", "gsection"),
  tune.type = c("gic", "ebic", "bic", "aic", "cv"),
  weight = rep(1, nrow(x)),
  normalize = NULL,
  c.max = 2,
  support.size = NULL,
  gs.range = NULL,
  always.include = NULL,
  max.splicing.iter = 20,
  screening.num = NULL,
  group.index = NULL,
  warm.start = TRUE,
  nfolds = 5,
  newton = c("exact", "approx"),
  newton.thresh = 1e-06,
  max.newton.iter = NULL,
  early.stop = FALSE,
  num.threads = 0,
  seed = 1,
  ...
)

\method{abess}{formula}(formula, data, subset, na.action, ...)
}
\arguments{
\item{x}{Input matrix, of dimension \eqn{n \times p}; each row is an observation
vector and each column is a predictor/feature/variable.}

\item{...}{further arguments to be passed to or from methods.}

\item{y}{The response variable, of \code{n} observations. For \code{family = "binomial"} should be
a factor with two levels. For \code{family="poisson"}, \code{y} should be a vector with positive integer.
 For \code{family = "cox"}, \code{y} should be a two-column matrix
with columns named \code{time} and \code{status}.}

\item{family}{One of the following models: \code{"gaussian"}, \code{"binomial"},
\code{"poisson"}, or \code{"cox"}. Depending on the response. Any unambiguous substring can be given.}

\item{method}{The method to be used to select the optimal model size and \eqn{L_2} shrinkage. For
\code{method = "sequential"}, we solve the best subset selection and the best subset ridge regression
problem for each \code{s} in \code{1,2,...,s.max} and \eqn{\lambda} in \code{lambda.list}. For \code{method =
"gsection"}, which is only valid for \code{type = "bss"},
we solve the best subset selection problem with model size ranged between s.min and s.max,
where the specific model size to be considered is determined by golden section. we
solve the best subset selection problem with a range of non-continuous model
sizes. For \code{method = "pgsection"} and \code{"psequential"}, the Powell method is used to
solve the best subset ridge regression problem. Any unambiguous substring can be given.}

\item{weight}{Observation weights. Default is \code{1} for each observation.}

\item{normalize}{Options for normalization. \code{normalize = 0} for
no normalization. Setting \code{normalize = 1} will
only subtract the mean of columns of \code{x}.
\code{normalize = 2} for scaling the columns of \code{x} to have \eqn{\sqrt n} norm.
\code{normalize = 3} for subtracting the means of the columns of \code{x} and \code{y}, and also
normalizing the columns of \code{x} to have \eqn{\sqrt n} norm.
If \code{normalize = NULL}, by default, \code{normalize} will be set \code{1} for \code{"gaussian"},
\code{2} for \code{"binomial"} and \code{"poisson"}, \code{3} for \code{"cox"}.}

\item{support.size}{An increasing list of sequential values representing the model
sizes. Only used for \code{method = "sequential"}. Default is \code{1:min(p,
round(n/log(n)))}.}

\item{always.include}{An integer vector containing the indexes of variables that should always be included in the model.}

\item{screening.num}{Users can pre-exclude some irrelevant variables according to maximum marginal likelihood estimators before fitting a
model by passing an integer to \code{screening.num} and the sure independence screening will choose a set of variables of this size.
Then the active set updates are restricted on this subset.}

\item{group.index}{A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of \code{x}
and their corresponding index in \code{group.index} should be the same.
Denote the first group as \code{1}, the second \code{2}, etc.
If you do not fit a model with a group structure,
please set \code{group.index = NULL}. Default is \code{NULL}.}

\item{warm.start}{Whether to use the last solution as a warm start. Default
is \code{TRUE}.}

\item{nfolds}{The number of folds in cross-validation. Default is \code{5}.}

\item{seed}{Seed to be used to devide the sample into K cross-validation folds. Default is \code{NULL}.}

\item{formula}{an object of class "\code{formula}": 
a symbolic description of the model to be fitted. 
The details of model specification are given in the "Details" section of "\code{\link{formula}}".}

\item{data}{a data frame containing the variables in the \code{formula}.}

\item{subset}{an optional vector specifying a subset of observations to be used.}

\item{na.action}{a function which indicates 
what should happen when the data contain \code{NA}s. 
Defaults to \code{getOption("na.action")}.}

\item{type}{One of the two types of problems.
\code{type = "bss"} for the best subset selection,
and \code{type = "bsrr"} for the best subset ridge regression.}

\item{tune}{The criterion for choosing the model size and \eqn{L_2} shrinkage
parameters. Available options are \code{"gic"}, \code{"ebic"}, \code{"bic"}, \code{"aic"} and \code{"cv"}.
Default is \code{"gic"}.}

\item{lambda.list}{A lambda sequence for \code{"bsrr"}. Default is
\code{exp(seq(log(100), log(0.01), length.out = 100))}.}

\item{s.min}{The minimum value of model sizes. Only used for \code{method =
"gsection"}, \code{"psequential"} and \code{"pgsection"}. Default is 1.}

\item{s.max}{The maximum value of model sizes. Only used for \code{method =
"gsection"}, \code{"psequential"} and \code{"pgsection"}. Default is \code{min(p, round(n/log(n)))}.}

\item{lambda.min}{The minimum value of lambda. Only used for \code{method =
"powell"}. Default is \code{0.001}.}

\item{lambda.max}{The maximum value of lambda. Only used for \code{method =
"powell"}. Default is \code{100}.}

\item{nlambda}{The number of \eqn{\lambda}s for the Powell path with sequential line search method.
Only valid for \code{method = "psequential"}.}

\item{max.iter}{The maximum number of iterations in the bess function.
In most of the case, only a few steps can guarantee the convergence. Default
is \code{20}.}
}
\value{
A list with class attribute 'bess' and named components:
\item{beta}{The best fitting coefficients.}
\item{coef0}{The best fitting
intercept.}
\item{bestmodel}{The best fitted model for \code{type = "bss"}, the class of which is \code{"lm"}, \code{"glm"} or \code{"coxph"}.}
\item{loss}{The training loss of the best fitting model.}
\item{ic}{The information criterion of the best fitting model when model
selection is based on a certain information criterion.} \item{cvm}{The mean
cross-validated error for the best fitting model when model selection is
based on the cross-validation.}
\item{lambda}{The lambda chosen for the best fitting model}
\item{beta.all}{For \code{bess} objects obtained by \code{gsection}, \code{pgsection}
and \code{psequential}, \code{beta.all} is a matrix with each column be the coefficients
of the model in each iterative step in the tuning path.
For \code{bess} objects obtained by \code{sequential} method,
A list of the best fitting coefficients of size
\code{s=0,1,...,p} and \eqn{\lambda} in \code{lambda.list} with the
smallest loss function. For \code{"bess"} objects of \code{"bsrr"} type, the fitting coefficients of the
\eqn{i^{th} \lambda} and the \eqn{j^{th}} \code{s} are at the \eqn{i^{th}}
list component's \eqn{j^{th}} column.}
\item{coef0.all}{For \code{bess} objects obtained from \code{gsection}, \code{pgsection} and \code{psequential},
\code{coef0.all} contains the intercept for the model in each iterative step in the tuning path.
For \code{bess} objects obtained from \code{sequential} path,
\code{coef0.all} contains the best fitting
intercepts of size \eqn{s=0,1,\dots,p} and \eqn{\lambda} in
\code{lambda.list} with the smallest loss function.}
\item{loss.all}{For \code{bess} objects obtained from \code{gsection}, \code{pgsection} and \code{psequential},
\code{loss.all} contains the training loss of the model in each iterative step in the tuning path.
For \code{bess} objects obtained from \code{sequential} path, this is a
list of the training loss of the best fitting intercepts of model size
\eqn{s=0,1,\dots,p} and \eqn{\lambda} in \code{lambda.list}. For \code{"bess"} object obtained by \code{"bsrr"},
the training loss of the \eqn{i^{th} \lambda} and the \eqn{j^{th}} \code{s}
is at the \eqn{i^{th}} list component's \eqn{j^{th}} entry.}
\item{ic.all}{For \code{bess} objects obtained from \code{gsection}, \code{pgsection} and \code{psequential},
\code{ic.all} contains the values of the chosen information criterion of the model in each iterative step in the tuning path.
For \code{bess} objects obtained from \code{sequential} path, this is a
matrix of the values of the chosen information criterion of model size \eqn{s=0,1,\dots,p}
and \eqn{\lambda} in \code{lambda.list} with the smallest loss function. For \code{"bess"} object obtained by \code{"bsrr"},
the training loss of the \eqn{i^{th} \lambda} and the \eqn{j^{th}}
\code{s} is at the \eqn{i^{th}} row \eqn{j^{th}} column. Only available when
model selection is based on a certain information criterion.}

\item{cvm.all}{For \code{bess} objects obtained from \code{gsection}, \code{pgsection} and \code{psequential},
\code{cvm.all} contains the mean cross-validation error of the model in each iterative step in the tuning path.
For \code{bess} objects obtained from \code{sequential} path, this is a
 matrix of the mean cross-validation error of model size
\eqn{s=0,1,\dots,p} and \eqn{\lambda} in \code{lambda.list} with the
smallest loss function. For \code{"bess"} object obtained by \code{"bsrr"}, the training loss of the \eqn{i^{th}
\lambda} and the \eqn{j^{th}} \code{s} is at the \eqn{i^{th}} row
\eqn{j^{th}} column. Only available when model selection is based on the
cross-validation.}
\item{lambda.all}{The lambda chosen for each step in \code{pgsection} and \code{psequential}.}
\item{family}{Type of the model.}
\item{support.size}{The input
\code{support.size}.} \item{nsample}{The sample size.}
\item{type}{Either \code{"bss"} or \code{"bsrr"}.}
\item{method}{Method used for tuning parameters selection.}
\item{ic.type}{The criterion of model selection.}
}
\description{
Performs the nonparametric two-sample or \eqn{K}-sample Ball Divergence test for
equality of multivariate distributions
}
\examples{

n <- 200
p <- 300
support.size <- 3
#-------------------linear model----------------------#
dataset <- generate.data(n, p, support.size)
abess_fit <- abess(dataset[["x"]], dataset[["y"]])
abess_fit[["best.model"]]

#-------------------logistic model----------------------#
dataset <- generate.data(n, p, support.size, family = "binomial")
abess_fit <- abess(dataset[["x"]], dataset[["y"]], family = "binomial")
abess_fit[["best.model"]]


################  Formula interface  ################
data("trim32")
abess_fit <- abess(y ~ ., data = trim32)
abess_fit
}
\references{
A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; DOI: 10.1073/pnas.2014241117
}
\seealso{
\code{\link{bess.fix}}
}
\author{
Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang
}
