---
title: "Power of abess"
author: "Liyuan Hu"
date: "2021/8/2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F, message = F)
```

## Simulation

To show the computational efficiency of abess, 
we compare abess R package with popular R libraries: glmnet, ncvreg for linear, logistic and poisson regressions; 
All these packages are compared in three aspects including the prediction performance, the variable selection performance and the computation efficiency.
The perdiction performance of the linear model is measured by $\|y - \hat{y}\|_2$ on a test set and for logistic regression this is measured by the area under the ROC Curve.
For the variable selection performance, we compute the true positive rate (TPR) and the false positive rate (FPR) of the fitted active set. 
Timings of the CPU execution are recorded in seconds and all the performance are averaged over 100 replications on a sequence
of 100 regularization parameters.


All experiments are
evaluated on an  Intel(R) Core(TM) i9-9940X CPU @ 3.30GHz 3.31 GHz and under R version 3.6.1. 

```r
source("R-package/example/perform.R")
```

The results are presented in the following pictures. First, among all of the methods implemented in different packages,
the estimator obtained by abess package shows the best prediction performance and can reasonably control the false-positive rate 
at a low level like SCAD and MCP. Furthermore, our abess package is highly efficient compared with 
other packages.


<center> Figure 1. Performance for different packages </center>

<img src='https://raw.githubusercontent.com/abess-team/abess/master/docs/perform/performance.png'/>


<center> Figure 2. Runing Time for different packages </center>

<img src='https://raw.githubusercontent.com/abess-team/abess/master/docs/perform/time_perform.png'/>
