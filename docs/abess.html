

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>abess package &mdash; abess 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="New page" href="new_page.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> abess
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation &amp; Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">abess package</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">abess package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-abess.cabess">abess.cabess module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-abess.gen_data">abess.gen_data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-abess.linear">abess.linear module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-abess">Module contents</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">New page</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="new_page.html">New page</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">abess</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>abess package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/abess.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="abess-package">
<h1>abess package<a class="headerlink" href="#abess-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-abess.cabess">
<span id="abess-cabess-module"></span><h2>abess.cabess module<a class="headerlink" href="#module-abess.cabess" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="abess.cabess.pywrap_abess">
<code class="sig-prename descclassname">abess.cabess.</code><code class="sig-name descname">pywrap_abess</code><span class="sig-paren">(</span><em class="sig-param">arg1</em>, <em class="sig-param">arg2</em>, <em class="sig-param">n</em>, <em class="sig-param">p</em>, <em class="sig-param">data_type</em>, <em class="sig-param">arg6</em>, <em class="sig-param">is_normal</em>, <em class="sig-param">algorithm_type</em>, <em class="sig-param">model_type</em>, <em class="sig-param">max_iter</em>, <em class="sig-param">exchange_num</em>, <em class="sig-param">path_type</em>, <em class="sig-param">is_warm_start</em>, <em class="sig-param">ic_type</em>, <em class="sig-param">ic_coef</em>, <em class="sig-param">is_cv</em>, <em class="sig-param">K</em>, <em class="sig-param">arg18</em>, <em class="sig-param">arg19</em>, <em class="sig-param">arg20</em>, <em class="sig-param">arg21</em>, <em class="sig-param">s_min</em>, <em class="sig-param">s_max</em>, <em class="sig-param">K_max</em>, <em class="sig-param">epsilon</em>, <em class="sig-param">lambda_min</em>, <em class="sig-param">lambda_max</em>, <em class="sig-param">n_lambda</em>, <em class="sig-param">is_screening</em>, <em class="sig-param">screening_size</em>, <em class="sig-param">powell_path</em>, <em class="sig-param">arg32</em>, <em class="sig-param">tau</em>, <em class="sig-param">primary_model_fit_max_iter</em>, <em class="sig-param">primary_model_fit_epsilon</em>, <em class="sig-param">early_stop</em>, <em class="sig-param">approximate_Newton</em>, <em class="sig-param">thread</em>, <em class="sig-param">covariance_update</em>, <em class="sig-param">sparse_matrix</em>, <em class="sig-param">arg41</em>, <em class="sig-param">arg42</em>, <em class="sig-param">arg43</em>, <em class="sig-param">arg44</em>, <em class="sig-param">arg45</em>, <em class="sig-param">arg46</em>, <em class="sig-param">arg47</em>, <em class="sig-param">arg48</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.cabess.pywrap_abess" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-abess.gen_data">
<span id="abess-gen-data-module"></span><h2>abess.gen_data module<a class="headerlink" href="#module-abess.gen_data" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="abess.gen_data.data">
<em class="property">class </em><code class="sig-prename descclassname">abess.gen_data.</code><code class="sig-name descname">data</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">beta</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.gen_data.data" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

<dl class="function">
<dt id="abess.gen_data.gen_data">
<code class="sig-prename descclassname">abess.gen_data.</code><code class="sig-name descname">gen_data</code><span class="sig-paren">(</span><em class="sig-param">n</em>, <em class="sig-param">p</em>, <em class="sig-param">family</em>, <em class="sig-param">k</em>, <em class="sig-param">rho=0</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">beta=None</em>, <em class="sig-param">censoring=True</em>, <em class="sig-param">c=1</em>, <em class="sig-param">scal=10</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.gen_data.gen_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="abess.gen_data.sample">
<code class="sig-prename descclassname">abess.gen_data.</code><code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">p</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.gen_data.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-abess.linear">
<span id="abess-linear-module"></span><h2>abess.linear module<a class="headerlink" href="#module-abess.linear" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="abess.linear.abessCox">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessCox</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessCox" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.abessLm">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessLm</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">covariance_update=False</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessLm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.abessLogistic">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessLogistic</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessLogistic" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.abessMLm">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessMLm</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">covariance_update=False</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessMLm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.abessMultinomial">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessMultinomial</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessMultinomial" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.abessPoisson">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">abessPoisson</code><span class="sig-paren">(</span><em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">path_type='seq'</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=None</em>, <em class="sig-param">lambda_max=None</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.abessPoisson" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#abess.linear.bess_base" title="abess.linear.bess_base"><code class="xref py py-class docutils literal notranslate"><span class="pre">abess.linear.bess_base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Examples</p>
<p>### Sparsity known
&gt;&gt;&gt; from bess.linear import *
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.random.seed(12345)
&gt;&gt;&gt; x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))
&gt;&gt;&gt; beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))
&gt;&gt;&gt; xbeta = np.matmul(x, beta)
&gt;&gt;&gt; p = np.exp(xbeta)/(1+np.exp(xbeta))
&gt;&gt;&gt; y = np.random.binomial(1, p)
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”, sequence=[5])
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<p>### Sparsity unknown
&gt;&gt;&gt; # path_type=”seq”, Default:sequence=[1,2,…,min(x.shape[0], x.shape[1])]
&gt;&gt;&gt; model = GroupPdasLogistic(path_type=”seq”)
&gt;&gt;&gt; model.fit(X=x, y=y)
&gt;&gt;&gt; model.predict(x)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GroupPdasLogistic</span><span class="p">(</span><span class="n">path_type</span><span class="o">=</span><span class="s2">&quot;pgs&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="abess.linear.bess_base">
<em class="property">class </em><code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">bess_base</code><span class="sig-paren">(</span><em class="sig-param">algorithm_type</em>, <em class="sig-param">model_type</em>, <em class="sig-param">path_type</em>, <em class="sig-param">max_iter=20</em>, <em class="sig-param">exchange_num=5</em>, <em class="sig-param">is_warm_start=True</em>, <em class="sig-param">sequence=None</em>, <em class="sig-param">lambda_sequence=None</em>, <em class="sig-param">s_min=None</em>, <em class="sig-param">s_max=None</em>, <em class="sig-param">K_max=None</em>, <em class="sig-param">epsilon=0.0001</em>, <em class="sig-param">lambda_min=0</em>, <em class="sig-param">lambda_max=0</em>, <em class="sig-param">ic_type='ebic'</em>, <em class="sig-param">ic_coef=1.0</em>, <em class="sig-param">is_cv=False</em>, <em class="sig-param">K=5</em>, <em class="sig-param">is_screening=False</em>, <em class="sig-param">screening_size=None</em>, <em class="sig-param">powell_path=1</em>, <em class="sig-param">always_select=[]</em>, <em class="sig-param">tau=0.0</em>, <em class="sig-param">primary_model_fit_max_iter=30</em>, <em class="sig-param">primary_model_fit_epsilon=1e-08</em>, <em class="sig-param">early_stop=False</em>, <em class="sig-param">approximate_Newton=False</em>, <em class="sig-param">thread=1</em>, <em class="sig-param">covariance_update=False</em>, <em class="sig-param">sparse_matrix=False</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.bess_base" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Max iteration time in PDAS.
Default: max_iter = 20.</p></li>
<li><p><strong>is_warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When search the best sparsity,whether use the last parameter as the initial parameter for the next search.
Default:is_warm_start = False.</p></li>
<li><p><strong>path_type</strong> (<em>{&quot;seq&quot;</em><em>, </em><em>&quot;pgs&quot;}</em>) – The method we use to search the sparsity。</p></li>
<li><p><strong>sequence</strong> (<em>array_like</em><em>, </em><em>optional</em>) – The  sparsity list for searching. If choose path_type = “seq”, we prefer you to give the sequence.If not
given, we will search all the sparsity([1,2,…,p],p=min(X.shape[0], X.shape[1])).
Default: sequence = None.</p></li>
<li><p><strong>s_min</strong> (<em>int</em><em>, </em><em>optional</em>) – The lower bound of golden-section-search for sparsity searching.If not given, we will set s_min = 1.
Default: s_min = None.</p></li>
<li><p><strong>s_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The higher bound of golden-section-search for sparsity searching.If not given, we will set s_max = p(p = X.shape[1]).
Default: s_max = None.</p></li>
<li><p><strong>K_max</strong> (<em>int</em><em>, </em><em>optional</em>) – The search times of golden-section-search for sparsity searching.If not given, we will set K_max = int(log(p, 2/(math.sqrt(5) - 1))).
Default: K_max = None.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em>) – The stop condition of golden-section-search for sparsity searching.
Default: epsilon = 0.0001.</p></li>
<li><p><strong>ic_type</strong> (<em>{'aic'</em><em>, </em><em>'bic'</em><em>, </em><em>'gic'</em><em>, </em><em>'ebic'}</em><em>, </em><em>optional</em>) – The metric when choose the best sparsity.
Input must be one of the set above. Default: ic_type = ‘ebic’.</p></li>
<li><p><strong>is_cv</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use the Cross-validation method to caculate the loss.
Default: is_cv = False.</p></li>
<li><p><strong>K</strong> (<em>int optional</em>) – The folds number when Use the Cross-validation method to caculate the loss.
Default: K = 5.</p></li>
<li><p><strong>Atrributes</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>beta</strong> (<em>array of shape</em><em> (</em><em>n_features</em><em>, </em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Estimated coefficients for the best subset selection problem.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><dl class="simple">
<dt>Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear,</dt><dd><p>logistic and coxph models]</p>
</dd>
</dl>
</li>
</ul>
<dl class="method">
<dt id="abess.linear.bess_base.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">is_weight=False</em>, <em class="sig-param">is_normal=True</em>, <em class="sig-param">weight=None</em>, <em class="sig-param">state=None</em>, <em class="sig-param">group=None</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.bess_base.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>The fit function is used to transfer the information of data and return the fit result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training data</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_targets</em><em>)</em>) – Target values. Will be cast to X’s dtype if necessary. For linear regression problem, y should be a n time 1 numpy array with type code{double}. For classification problem, code{y} should be a $n       ime 1$ numpy array with values code{0} or code{1}. For count data, code{y} should be a $n    ime 1$ numpy array of non-negative integer.</p></li>
<li><p><strong>is_weight</strong> (<em>bool</em>) – whether to weight sample yourself.
Default: is$_$weight = False.</p></li>
<li><p><strong>is_normal</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether normalize the variables array before fitting the algorithm.
Default: is$_$normal=True.</p></li>
<li><p><strong>weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Individual weights for each sample. If set is$_$weight = True, weight should be given.
Default: code{weight} = code{numpy.ones(n)}.</p></li>
<li><p><strong>group</strong> (<em>int</em><em>, </em><em>optional</em>) – The group index for each variable.
Default: code{group} = code{numpy.ones(p)}.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="abess.linear.bess_base.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.bess_base.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>The predict function is used to give prediction for new data.</p>
<p>We will return the prediction of response variable.
For linear and poisson regression problem, we return a numpy array of the prediction of the mean.
For classification problem, we return a code{dict} of code{pr} and code{y}, where code{pr} is the probability of response variable is 1 and code{y} is predicted to be 1 if code{pr} &gt; 0.5 else code{y} is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test data.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="abess.linear.fix_docs">
<code class="sig-prename descclassname">abess.linear.</code><code class="sig-name descname">fix_docs</code><span class="sig-paren">(</span><em class="sig-param">cls</em><span class="sig-paren">)</span><a class="headerlink" href="#abess.linear.fix_docs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-abess">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-abess" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="new_page.html" class="btn btn-neutral float-right" title="New page" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Kangkang Jiang.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>