
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_gallery/3advancedfeatures/plot_regularized.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_gallery_3advancedfeatures_plot_regularized.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_gallery_3advancedfeatures_plot_regularized.py:


Regularized Adaptive Best Subset Selection
================================================

.. GENERATED FROM PYTHON SOURCE LINES 6-14

In some cases, especially under low signal-to-noise ratio (SNR) setting or predictors are highly correlated, the vallina type of :math:`L_0` constrained model may not be satisfying and a more sophisticated trade-off between bias and variance is needed. Under this concern, the `abess` pakcage provides option of best subset selection with :math:`L_2` norm regularization called the regularized bess. The model has this following form:

.. math::
    \arg\min_\beta L(\beta) + \alpha \|\beta\|_2^2.

To implement the regularized bess, user need to specify a value to an additive argument `alpha` in the `LinearRegression()` function (or other methods). This value corresponds to the penalization parameter in the model above. 

Letâ€™s test the regularized best subset selection against the no-regularized one over 100 replicas in terms of prediction performance. With argument `snr` in `make_glm_data()`, we can add white noise into generated data.

.. GENERATED FROM PYTHON SOURCE LINES 14-40

.. code-block:: default

    import numpy as np
    from abess.datasets import make_glm_data
    from abess.linear import LinearRegression

    np.random.seed(0)

    loss = np.zeros((2, 100))
    coef = np.repeat([1, 0], [5, 25])
    for i in range(100):
        np.random.seed(i)
        train = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)
        np.random.seed(i + 100)
        test = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)
    
        # normal
        model = LinearRegression()
        model.fit(train.x, train.y)
        loss[0, i] = np.linalg.norm(model.predict(test.x) - test.y)
        # regularized
        model = LinearRegression(alpha = 0.7)
        model.fit(train.x, train.y)
        loss[1, i] = np.linalg.norm(model.predict(test.x) - test.y)

    print("normal model's loss:", np.mean(loss[0,:]))
    print("regularized model's loss:", np.mean(loss[1,:]))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    normal model's loss: 24.740937201741712
    regularized model's loss: 28.332125562008272




.. GENERATED FROM PYTHON SOURCE LINES 41-42

The regularized model has a lower test loss. And we can also make a boxplot:

.. GENERATED FROM PYTHON SOURCE LINES 42-48

.. code-block:: default



    import matplotlib.pyplot as plt
    plt.boxplot([loss[0,:], loss[1,:]], labels = ['ABESS', 'RABESS'])
    plt.show()




.. image-sg:: /auto_gallery/3advancedfeatures/images/sphx_glr_plot_regularized_001.png
   :alt: plot regularized
   :srcset: /auto_gallery/3advancedfeatures/images/sphx_glr_plot_regularized_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 49-54

We see that the regularized best subset select ("RABESS" in figure)  indeed reduces the prediction error.

R tutorial
-----------------------
For R tutorial, please view [https://abess-team.github.io/abess/articles/v07-advancedFeatures.html](https://abess-team.github.io/abess/articles/v07-advancedFeatures.html).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.400 seconds)


.. _sphx_glr_download_auto_gallery_3advancedfeatures_plot_regularized.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_regularized.py <plot_regularized.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_regularized.ipynb <plot_regularized.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
