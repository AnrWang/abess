{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regularized Adaptive Best Subset Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some cases, especially under low signal-to-noise ratio (SNR) setting or predictors are highly correlated, the vallina type of $L_0$ constrained model may not be satisfying and a more sophisticated trade-off between bias and variance is needed. Under this concern, the `abess` pakcage provides option of best subset selection with $L_2$ norm regularization called the regularized bess. The model has this following form:\n\n\\begin{align}\\arg\\min_\\beta L(\\beta) + \\alpha \\|\\beta\\|_2^2.\\end{align}\n\nTo implement the regularized bess, user need to specify a value to an additive argument `alpha` in the `LinearRegression()` function (or other methods). This value corresponds to the penalization parameter in the model above. \n\nLet\u2019s test the regularized best subset selection against the no-regularized one over 100 replicas in terms of prediction performance. With argument `snr` in `make_glm_data()`, we can add white noise into generated data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom abess.datasets import make_glm_data\nfrom abess.linear import LinearRegression\n\nnp.random.seed(0)\n\nloss = np.zeros((2, 100))\ncoef = np.repeat([1, 0], [5, 25])\nfor i in range(100):\n    np.random.seed(i)\n    train = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)\n    np.random.seed(i + 100)\n    test = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)\n    \n    # normal\n    model = LinearRegression()\n    model.fit(train.x, train.y)\n    loss[0, i] = np.linalg.norm(model.predict(test.x) - test.y)\n    # regularized\n    model = LinearRegression(alpha = 0.7)\n    model.fit(train.x, train.y)\n    loss[1, i] = np.linalg.norm(model.predict(test.x) - test.y)\n\nprint(\"normal model's loss:\", np.mean(loss[0,:]))\nprint(\"regularized model's loss:\", np.mean(loss[1,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The regularized model has a lower test loss. And we can also make a boxplot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.boxplot([loss[0,:], loss[1,:]], labels = ['ABESS', 'RABESS'])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the regularized best subset select (\"RABESS\" in figure)  indeed reduces the prediction error.\n\n## R tutorial\nFor R tutorial, please view [https://abess-team.github.io/abess/articles/v07-advancedFeatures.html](https://abess-team.github.io/abess/articles/v07-advancedFeatures.html).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}