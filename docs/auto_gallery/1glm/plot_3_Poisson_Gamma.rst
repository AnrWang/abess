
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_gallery/1glm/plot_3_Poisson_Gamma.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_gallery_1glm_plot_3_Poisson_Gamma.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_gallery_1glm_plot_3_Poisson_Gamma.py:


=======================================================
Positive response: Poisson and Gamma regression
=======================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-24

Poisson Regression
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Poisson Regression involves regression models in which the response variable is in the form of counts. For example, the count of number of car accidents or number of customers in line at a reception desk. The expectation of the response variables is assumed to follow a Poisson distribution.

The general mathematical equation for Poisson regression is

.. math::
  \log(E(y)) = \beta_0 + \beta_1 X_1+\beta_2 X_2+\dots+\beta_p X_p.


Simulated Data Example
""""""""""""""""""""""""

We generate some artificial data using this logic.
Consider a dataset containing `n=100` observations with `p=6` variables. The `make_glm_data()` function allows uss to generate simulated data. By specifying `k = 3`, we set only 3 of the 6 variables to have effect on the expectation of the response. 


.. GENERATED FROM PYTHON SOURCE LINES 24-38

.. code-block:: default


    import numpy as np
    from abess.datasets import make_glm_data
    np.random.seed(0)

    n = 100
    p = 6
    k = 3
    data = make_glm_data(n = n, p = p , k = k, family="poisson")
    print("non-zero:\n", np.nonzero(data.coef_))
    print("real coef:\n", data.coef_)
    print("the first 5 x:\n", data.x[0:5,])
    print("the first 5 y:\n",data.y[0:5])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    non-zero:
     (array([0, 2, 5]),)
    real coef:
     [8.97519346 0.         7.74067053 0.         0.         6.51945346]
    the first 5 x:
     [[ 0.10206398  0.02183018  0.07262124  0.14137693  0.13114375 -0.05882929]
     [ 0.05416649 -0.0097946   0.00670931  0.02410382  0.01464568  0.10943946]
     [ 0.04304185  0.00586154  0.04003711  0.01917503  0.10589907 -0.0053969 ]
     [ 0.01668117 -0.05009082 -0.14252873  0.03967493  0.06333941 -0.04255895]
     [ 0.1318219  -0.08451131  0.01578489 -0.0141981   0.10851494  0.1104834 ]]
    the first 5 y:
     [0 3 0 1 9]




.. GENERATED FROM PYTHON SOURCE LINES 39-42

Model Fitting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
The `PoissonRegression()` function in the **abess** package allows you to perform best subset selection in a highly efficient way. We can call the function using formula like: 

.. GENERATED FROM PYTHON SOURCE LINES 42-49

.. code-block:: default



    from abess.linear import PoissonRegression

    model = PoissonRegression(support_size = range(7))
    model.fit(data.x, data.y)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    PoissonRegression(support_size=range(0, 7))



.. GENERATED FROM PYTHON SOURCE LINES 50-51

where `support_size` contains the level of sparsity we consider, and the program can adaptively choose the "best" one. The result of coefficients can be viewed through `model.coef_`:

.. GENERATED FROM PYTHON SOURCE LINES 51-56

.. code-block:: default




    print(model.coef_)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[6.97861535]
     [0.        ]
     [7.00639571]
     [0.        ]
     [0.        ]
     [7.23806417]]




.. GENERATED FROM PYTHON SOURCE LINES 57-62

So that the first, third and last variables are thought to be useful in the model (the chosen sparsity is 3), which is the same as "real" variables. What's more, the predicted coefficients are also close to the real ones.

More on the Results
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Actually, we can also plot the path of coefficients in abess process. This can be computed by fixing the `support_size` as one number from 0 to 6 each time:

.. GENERATED FROM PYTHON SOURCE LINES 62-83

.. code-block:: default




    import matplotlib.pyplot as plt

    coef = np.zeros((7, 6))
    ic = np.zeros(7)
    for s in range(7):
        model = PoissonRegression(support_size = s)
        model.fit(data.x, data.y)
        coef[s, :] = model.coef_
        ic[s] = model.ic_

    for i in range(6):
        plt.plot(coef[:, i], label = i)

    plt.xlabel('support_size')
    plt.ylabel('coefficients')
    plt.legend()
    plt.show()



.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/home/hjh/Documents/github/abess/docs/Tutorial/1glm/plot_3_Poisson_Gamma.py", line 72, in <module>
        coef[s, :] = model.coef_
    ValueError: could not broadcast input array from shape (6,1) into shape (6,)




.. GENERATED FROM PYTHON SOURCE LINES 84-85

And the evolution of information criterion (by default, we use EBIC):

.. GENERATED FROM PYTHON SOURCE LINES 85-93

.. code-block:: default




    plt.plot(ic, 'o-')
    plt.xlabel('support_size')
    plt.ylabel('EBIC')
    plt.show()


.. GENERATED FROM PYTHON SOURCE LINES 94-117

The lowest point is shown on `support_size=3` and that's why the program chooses 3 variables as output.

Gamma Regression
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Gamma regression can be used when you have positive continuous response variables such as payments for insurance claims, or the lifetime of a redundant system. It is well known that the density of Gamma distribution can be represented as a function of a mean parameter (:math:`\mu`) and a shape parameter (:math:`\alpha`), respectively,

.. math::
  f(y \mid \mu, \alpha)=\frac{1}{y \Gamma(\alpha)}\left(\frac{\alpha y}{\mu}\right)^{\alpha} e^{-\alpha y / \mu} {I}_{(0, \infty)}(y),


where :math:`I(\cdot)` denotes the indicator function. In the Gamma regression model, response variables are assumed to follow Gamma distributions. Specifically, 

.. math::
  y_i \sim Gamma(\mu_i, \alpha),


where :math:`1/\mu_i = x_i^T\beta`.

Compared with Poisson regression, this time we consider the response variables as (continuous) levels of satisfaction.

Simulated Data Example
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Firstly, we also generate data from `make_glm_data()`, but `family = "gamma"` is given this time:

.. GENERATED FROM PYTHON SOURCE LINES 117-131

.. code-block:: default


    import numpy as np
    from abess.datasets import make_glm_data
    np.random.seed(1)

    n = 100
    p = 6
    k = 3
    data = make_glm_data(n = n, p = p , k = k, family = "gamma")
    print("non-zero:\n", np.nonzero(data.coef_))
    print("real coef:\n", data.coef_)
    print("the first 5 x:\n", data.x[0:5,])
    print("the first 5 y:\n", data.y[0:5])


.. GENERATED FROM PYTHON SOURCE LINES 132-135

Model Fitting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We apply the above procedure for gamma regression simply by using `abess.linear.GammaRegression`. It has similar member functions for fitting.

.. GENERATED FROM PYTHON SOURCE LINES 135-143

.. code-block:: default




    from abess.linear import GammaRegression

    model = GammaRegression(support_size = range(7), cv = 5) # use CV (fold = 5) for fitting
    model.fit(data.x, data.y)


.. GENERATED FROM PYTHON SOURCE LINES 144-145

The fitted coefficients:

.. GENERATED FROM PYTHON SOURCE LINES 145-150

.. code-block:: default



    print(model.coef_)



.. GENERATED FROM PYTHON SOURCE LINES 151-154

More on the Results
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We can also plot the path of coefficients in abess process.

.. GENERATED FROM PYTHON SOURCE LINES 154-175

.. code-block:: default




    import matplotlib.pyplot as plt

    coef = np.zeros((7, 6))
    loss = np.zeros(7)
    for s in range(7):
        model = GammaRegression(support_size = s)
        model.fit(data.x, data.y)
        coef[s, :] = model.coef_
        loss[s] = model.test_loss_

    for i in range(6):
        plt.plot(coef[:, i], label = i)

    plt.xlabel('support_size')
    plt.ylabel('coefficients')
    plt.legend()
    plt.show()


.. GENERATED FROM PYTHON SOURCE LINES 176-179

R tutorial
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For R tutorial, please view [https://abess-team.github.io/abess/articles/v04-PoissonGammaReg.html](https://abess-team.github.io/abess/articles/v04-PoissonGammaReg.html).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.006 seconds)


.. _sphx_glr_download_auto_gallery_1glm_plot_3_Poisson_Gamma.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_3_Poisson_Gamma.py <plot_3_Poisson_Gamma.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_3_Poisson_Gamma.ipynb <plot_3_Poisson_Gamma.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
